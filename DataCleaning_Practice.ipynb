{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------\n",
    "#DATA CLEANING OPTIONS:\n",
    "#---------------------------\n",
    "\n",
    "#Import File\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('file_path')\n",
    "df2 = pd.read_excel('file_path')\n",
    "df3 = pd.read_sql('file_path')\n",
    "\n",
    "#Preview dataset / print functions\n",
    "df.info() #view column names, non-Null count, column data types\n",
    "df #Print 1st and last 5 rows\n",
    "print(df) #Print 1st and last 5 rows in a different format\n",
    "print(df.head(10)) #Print 1st 10 rows\n",
    "print(df.tail(12)) #Print last 12 rows\n",
    "print(df.to_string()) #View entire dataset\n",
    "\n",
    "#Finding null values via columns\n",
    "#True = Is Null\n",
    "#False = NOT Null\n",
    "df.isnull()\n",
    "\n",
    "# HANDLING MISSING VALUES:\n",
    "    # Identify Missing Values + sums up missing values: df.isnull().sum()\n",
    "    # Drop Rows with Missing Values: df.dropna()\n",
    "    # Drop Columns with Missing Values: df.dropna(axis=1)\n",
    "    # Fill Missing Values with a Constant: df.fillna(value)\n",
    "    # Fill Missing Values with Mean/Median/Mode: df.fillna(df.mean())\n",
    "    # Forward Fill Missing Values: df.ffill()\n",
    "    # Backward Fill Missing Values: df.bfill()\n",
    "    # Interpolate Missing Values: df.interpolate()\n",
    "\n",
    "#Remove nulls\n",
    "dropnulls1 = df.dropna() #Drops nulls in new dataframe\n",
    "df.dropna(inplace = True) #Drops nulls from original dataframe\n",
    "\n",
    "#Replace Nulls with values\n",
    "df.fillna(130, inplace=True) #Replace all nulls with 130\n",
    "df['Column1'].fillna('Blank', inplace=True) #Replace nulls in only 1 column\n",
    "\n",
    "#Remove unnecessary columns\n",
    "#axis=1 = columns\n",
    "#axis=0 = rows\n",
    "df.drop('column_name', axis=1, inplace=True)\n",
    "\n",
    "#Rename only selected columns:\n",
    "df.rename(columns={\n",
    "    'G': 'Gender',\n",
    "    'A': 'Age', \n",
    "    'ES': 'Employment Status'\n",
    "}, inplace=True)\n",
    "\n",
    "#Replace (rename) values:\n",
    "df.replace(to_replace='N', value = 'North')\n",
    "\n",
    "#Determine data types for all columns\n",
    "df.dtypes\n",
    "\n",
    "df.astype(str) #Change dataframe to a string\n",
    "df.astype({'Age': int}) #Change column to an integer\n",
    "\n",
    "#Finding distinct info in columns\n",
    "df['Employment Status'].unique()\n",
    "\n",
    "#Determine distinct info in column + calc. stats (mean, min, etc.)\n",
    "df.groupby('Employment Status').describe()\n",
    "\n",
    "#Calculates totals for each distinct value\n",
    "df['Employment Status'].value_counts()\n",
    "\n",
    "#Locate duplicated data in specified columns\n",
    "df.duplicated(['Age', 'Employment Status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use pandas to clean data\n",
    "import pandas as pd\n",
    "\n",
    "#Import file\n",
    "df = pd.read_csv(\n",
    "    'C:\\\\Users\\Danielle\\Documents\\DAP\\Data Science and Capstone\\MASTERChildlessnessNJ.csv')\n",
    "#Another import file option to parse by time\n",
    "# df = pd.read_csv(file_name, parse_dates=['time']\n",
    "\n",
    "#View 10 random rows in data\n",
    "#Each time you hit run, it will generate new rows\n",
    "df.sample(10)\n",
    "\n",
    "\n",
    "#Finding null values via rows\n",
    "#Issue: Pandas will convert int to floats if their are missing int values\n",
    "#Solution: Pandas has \"pandas.arrays.IntegerArray()\", which allows missing values in int\n",
    "# df.isnull().any(axis=1)\n",
    "\n",
    "#Identify nulls + empty strings\n",
    "import numpy as np\n",
    "EmptyStrings = df['Q7'].str.strip() == ''\n",
    "df.loc[EmptyStrings, 'Q7'] = np.nan\n",
    "\n",
    "df.isnull().any(axis=1)\n",
    "\n",
    "#Only show rows that are greater or less than a set amount\n",
    "    #Ex: Want to only view participants that are >25 years old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use pandas to clean data\n",
    "import pandas as pd\n",
    "\n",
    "#Import file\n",
    "df = pd.read_csv(\n",
    "    'C:\\\\Users\\Danielle\\Documents\\DAP\\Data Science and Capstone\\MASTERChildlessnessNJ.csv')\n",
    "\n",
    "\n",
    "#Ways to find bas values:\n",
    "\n",
    "#Finding distinct info in columns\n",
    "# Employment = df['Employment Status'].unique()\n",
    "# print(Employment)\n",
    "\n",
    "#Determine distinct info in column + calc. stats (mean, min, etc.)\n",
    "# df.groupby('Gender').describe()\n",
    "# df.groupby('Age').describe()\n",
    "df.groupby('Employment Status').describe()\n",
    "# df.groupby('Race/Ethnicity').describe()\n",
    "# df.groupby('Relationship Status').describe()\n",
    "# df.groupby('Currently have children').describe()\n",
    "# df.groupby('Q1').describe()\n",
    "\n",
    "#Calculates totals for each distinct value\n",
    "# df['Employment Status'].value_counts()\n",
    "\n",
    "#Can find bad values through chart form. Some people find this easier. \n",
    "#DID NOT WORK FOR ME????...\n",
    "# pd.pivot(df, index='Age', columns='Employment Status').plot(subplots=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Locate duplicated data\n",
    "# df.duplicated()\n",
    "\n",
    "#Locate duplicated data in specified columns\n",
    "df.duplicated(['Age', 'Employment Status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Schema\n",
    "#DID NOT WORK FOR ME????\n",
    "\n",
    "# import pandera as pa\n",
    "\n",
    "# schema = pa.DataFrameSchema({\n",
    "#     'Age': pa.Column(pa.Float, nullable=True),\n",
    "#     'Gender': pa.Column(pa.String, nullable=True), \n",
    "#     'Employment Status': pa.Column(pa.String, nullable=True)\n",
    "# })\n",
    "\n",
    "# schema.validate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use pandas to clean data\n",
    "import pandas as pd\n",
    "\n",
    "#Import file\n",
    "df = pd.read_csv(\n",
    "    'C:\\\\Users\\Danielle\\Documents\\DAP\\Data Science and Capstone\\MASTERChildlessnessNJ.csv')\n",
    "\n",
    "#Identify ages greater than or equal to 25\n",
    "#Idenfity ages less than 25\n",
    "HigherAge = df['Age'] >= 25\n",
    "LowerAge = df['Age'] < 25\n",
    "\n",
    "#Print the age ranges\n",
    "# df[HigherAge]\n",
    "df[LowerAge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns:\n",
    "#Use pandas to clean data\n",
    "import pandas as pd\n",
    "\n",
    "#Import file\n",
    "df = pd.read_csv(\n",
    "    'C:\\\\Users\\Danielle\\Documents\\DAP\\Data Science and Capstone\\MASTERChildlessnessNJ.csv')\n",
    "\n",
    "#Rename all columns:\n",
    "# col_names = ['Gender','Age','Employment Status','Race/Ethnicity','Relationship Status',\n",
    "#     'Currently have children','F1','F2','F3','F4','F5','F6','F7','C8','C9','C10','C11',\n",
    "#     'C12','OI13','OI14','OI15','OI16','OI17','OI18','OI19','OI20','H21','H22','H23','H24','H25',\n",
    "#     'H26','H27','H28','H29','H30']\n",
    "# df = pd.read_csv(\n",
    "#     'C:\\\\Users\\Danielle\\Documents\\DAP\\Data Science and Capstone\\MASTERChildlessnessNJ.csv'\n",
    "#     , names = col_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to further rename columns:\n",
    "#Below coding is from a tutorial video for a completely differnt file\n",
    "'''\n",
    "Fix column name by:\n",
    "-removing numericals\n",
    "-changing to all lower case and \n",
    "-replacing spaces with underscore\n",
    "    fix_col('1.First Name')\n",
    "'first_name'\n",
    "'''\n",
    "\n",
    "#----------------\n",
    "#Import commands:\n",
    "#----------------\n",
    "# import pandas as pd\n",
    "# df = pd.read_csv('file_path')\n",
    "# df\n",
    "\n",
    "# import re\n",
    "\n",
    "\n",
    "#---------------------------\n",
    "#Function to rename columns:\n",
    "#---------------------------\n",
    "#re.sub = substitute\n",
    "    # r'\\d+.\\s+ = regular expression with a number (1+), period, and a space\n",
    "    # , '' = convert 1. to nothing\n",
    "def fix_col(col):\n",
    "    return (\n",
    "        re.sub(r'\\d+.\\s+', '', col)\n",
    "        .lower()\n",
    "        .replace(' ', '_')\n",
    "    )\n",
    "\n",
    "df. rename(columns=fix_col, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing data types:\n",
    "import pandas as pd\n",
    "\n",
    "#Import file\n",
    "df = pd.read_csv(\n",
    "    'C:\\\\Users\\Danielle\\Documents\\DAP\\Data Science and Capstone\\MASTERChildlessnessNJ.csv')\n",
    "\n",
    "#Display all datatypes:\n",
    "#object = string\n",
    "df.dtypes\n",
    "\n",
    "#Create a function to replace data types:\n",
    "#Q3 = float, change to an integer\n",
    "#val = value\n",
    "#base=0 = get the base from the string\n",
    "\n",
    "#RECEIVED AN ERROR!!!\n",
    "# def asint(val):\n",
    "#     return int(val, base=0)\n",
    "\n",
    "# df['Q3'] = df['Q3'].apply(asint)\n",
    "# df.dtypes\n",
    "\n",
    "#Create a dictionary to convert values to boolean\n",
    "#NO ERROR, BUT DID NOT CHANGE FROM OBJECT TO BOOLEAN\n",
    "# bools = {\n",
    "#     'yes': True, \n",
    "#     'no': False, \n",
    "# }\n",
    "\n",
    "# df['Relationship Status'] = df['Relationship Status'].map(bools)\n",
    "# df.dtypes\n",
    "\n",
    "#Run file\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting a columns values into two columns\n",
    "#Ex: Time columns values are listed as 0:00-0:00\n",
    "\n",
    "times = df['time'].str.split('_', expand=True)\n",
    "#Two new columns created that are named 'start' and 'end'\n",
    "times.columns = ['start', 'end']\n",
    "times\n",
    "\n",
    "#Use concat to join original df with the two new columns\n",
    "    #So will include the original date column w/the start & end columns included\n",
    "#axis = 1 means perform the concat horizontally\n",
    "#sep=T means including a date stamp with the start & end times\n",
    "df = pd.concat([df, times], axis=1)\n",
    "df\n",
    "df['start'] = pd.to_datetime(\n",
    "    df['date'].str.cat(df['start'], sep='T')\n",
    "\n",
    ")\n",
    "\n",
    "#Totals all times listed. \n",
    "#Ex: the times indicate how long you walked each day and it gives the total over all of the days. \n",
    "(df['end'] - df['start']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete bad rows. \n",
    "'''\n",
    "Don't want rows where age is less than 25. \n",
    "Below code did not work for me. \n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#Import file\n",
    "df = pd.read_csv(\n",
    "    'C:\\\\Users\\Danielle\\Documents\\DAP\\Data Science and Capstone\\MASTERChildlessnessNJ.csv')\n",
    "\n",
    "\n",
    "age2 = df.eval('Employment Status.isnull() | age <=25')\n",
    "age2\n",
    "\n",
    "df = df[~age]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling missing values\n",
    "\n",
    "'''\n",
    "Ex: \n",
    "\n",
    "#Replace blank cell with \"1\"\n",
    "df['column1'].fillna(1, inplace=True)\n",
    "df\n",
    "\n",
    "#Replace blank cell in column2 with the most common value in the column. \n",
    "#Ex: if potato occurs the most in column2, \n",
    "    #then potato will be placed in the null cell\n",
    "most_common = df['column2'].mode()[0]\n",
    "df['column1'].fillna(column2, inplace=True)\n",
    "df\n",
    "\n",
    "#Replace null value with value in cell above it.\n",
    "#This is great for a time series column\n",
    "#ffill = forward fill\n",
    "df['column3'].fillna(method='ffill', inplace=True)\n",
    "df\n",
    "\n",
    "#Replace null value with mean\n",
    "import numpy as np\n",
    "column3 = df.groupby('column1')['column3'].transform(np.mean)\n",
    "column3\n",
    "\n",
    "df['column3'].fillna(column3, inplace=True)\n",
    "df\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape data using pandas.melt function\n",
    "\n",
    "'''\n",
    "Ex:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df.pd.read_csv('file')\n",
    "df\n",
    "\n",
    "df = pd.melt(\n",
    "    df, \n",
    "    value_vars=['column1', 'column2'],\n",
    "    id_vars=['column3'],\n",
    "    car_name='NameofNewVariable',\n",
    ")\n",
    "df\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix data types\n",
    "    #Can use functions to change datatypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a variable for the file path:\n",
    "excel_file_path = 'office_info.xlsx'\n",
    "df = pd,read_excel(excel_file_path)\n",
    "\n",
    "#In the Name Column: \n",
    "#Replace data type to a string (.str)\n",
    "#AND replace anything that is NOT a letter or number with nothing (.replace(r'\\W', \"\"))\n",
    "df['Name'] = df['Name'].str.replace(r'\\W', \"\")\n",
    "\n",
    "#Applying above syntax to ALL columns:\n",
    "for column in df.column.columns:\n",
    "    df[column] = df[column].str.replace(r'\\W', \"\")\n",
    "\n",
    "#Move changes to a new excel file:\n",
    "df.to_excel(\"removed_characters.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SECTION 3.3 PYTHON FLOW CONTROL:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#scores_df = pd.read_excel('sample_scores.xlsx')\n",
    "\n",
    "#Average two columns into a new column named \"average\"\n",
    "scores_df['average'] = score_df.mean(axis=1)\n",
    "\n",
    "#Define in a new column who passes and fails, based on grade scores:\n",
    "#The following is similar to Excels If statement:\n",
    "scores_df['Pass/Fail'] = np.where(scores_df['average'] > 60, 'Pass', 'Fail')\n",
    "\n",
    "#Defining more than one condition and the corresponding results:\n",
    "conditions = [\n",
    "(scores_df['average'] >= 90),\n",
    "(scores_df['average'] < 90) & (scores_df['average'] >=80),\n",
    "(scores_df['average'] < 80) & (scores_df['average'] >=70),\n",
    "(scores_df['average'] < 70) & (scores_df['average'] >=60),\n",
    "(scores_df['average'] <60)\n",
    "]\n",
    "\n",
    "results = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "scores_df['Letter Grade'] = np.select(conditions, results)\n",
    "\n",
    "#Using IF statement instead. \n",
    "scores_df['Pass/Fail'] = ['Pass' if x > 60 else 'fail' for x in scores_df['average']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SECTION 4.1 PYTHON MODULES / FUNCTIONS:\n",
    "\n",
    "# using Date Time\n",
    "import datetime as dt\n",
    "\n",
    "# Get Current Date and Time\n",
    "a = dt.datetime.now()\n",
    "print(\"Current Date and Time ...\", a)\n",
    "# Get just the Date\n",
    "b = dt.date.today()\n",
    "print(\"Just the Date ...\", b)\n",
    "# Create a date object to represent a specific date\n",
    "c = dt.datetime(2020, 5, 17) \n",
    "\n",
    "print(\"Presenting a specific date ...\", c)\n",
    "# Find parts of the date string\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "\n",
    "# Print today's year, month and day\n",
    "print(\"Current year:\", today.year)\n",
    "print(\"Current month:\", today.month)\n",
    "print(\"Current day:\", today.day)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "\n",
    "# \"strftime()\" EXAMPLES\n",
    "import datetime\n",
    "example = datetime.datetime.now()\n",
    "\n",
    "print(\"Day ... \", example.strftime(\"%A\"))\n",
    "print(\"Month ...\", example.strftime(\"%B\"))\n",
    "print(\"Year ...\", example.strftime(\"%Y\"))\n",
    "print(\"24 Hour time ...\", example.strftime(\"%H\"))\n",
    "print(\"Minutes ...\", example.strftime(\"%M\"))\n",
    "\n",
    "#---------------------------------------------------------\n",
    "\n",
    "# Import math library\n",
    "import math\n",
    "\n",
    "# Round a number upward to its nearest integer\n",
    "print(\"Round up ... \", math.ceil(1.4))\n",
    "\n",
    "#Print absolute values from numbers\n",
    "print(\"Absolute value ...\", math.fabs(-66.43))\n",
    "\n",
    "#Return factorial of a number\n",
    "print(\"Factorial ...\", math.factorial(12))      # interesting fact -- max factorial 170\n",
    "\n",
    "# Print the sum of all items\n",
    "print(\"Sum ...\", math.fsum([1.7, 0.3, 1.5, 4.5]))\n",
    "\n",
    "# Return the square root of different numbers\n",
    "print(\"Square root ...\", math.sqrt(225))\n",
    "print(\"Square ...\", 15.0**2)\n",
    "\n",
    "# Print the value of pi\n",
    "print (\"Print PI ...\", math.pi)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "\n",
    "# using random methods\n",
    "import random\n",
    "\n",
    "# Return a number between 1 and 10:\n",
    "diceThrow=random.randrange(1,21)\n",
    "print(\"Dice throw ...\", diceThrow)\n",
    "\n",
    "# Return random number between 0.0 and 1.0:\n",
    "prob = random.random()\n",
    "print(\"Probability ...\", prob)\n",
    "\n",
    "# Shuffle a list (reorganize the order of the list items):\n",
    "orderedList = [\"apple\", \"banana\", \"cherry\"]\n",
    "random.shuffle(orderedList)\n",
    "print(\"Shuffled List ...\", orderedList)\n",
    "\n",
    "# Return a random element from a list:\n",
    "myList = [\"apple\", \"banana\", \"cherry\"]\n",
    "print(\"Random element ...\", random.choice(myList))\n",
    "\n",
    "#----------------------------------------------------------\n",
    "#PYTHON EXCEPTION HANDLING:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
